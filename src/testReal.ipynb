{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 16:23:15.992629: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# tf tools\n",
    "import tensorflow as tf\n",
    "\n",
    "# image processsing\n",
    "from tensorflow.keras.preprocessing.image import (load_img,\n",
    "                                                  img_to_array,\n",
    "                                                  ImageDataGenerator)\n",
    "# VGG16 model\n",
    "from tensorflow.keras.applications.vgg16 import (preprocess_input,\n",
    "                                                 decode_predictions,\n",
    "                                                 VGG16)\n",
    "# cifar10 data - 32x32\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# layers\n",
    "from tensorflow.keras.layers import (Flatten, \n",
    "                                     Dense, \n",
    "                                     Dropout, \n",
    "                                     BatchNormalization)\n",
    "# generic model object\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are unzipped\n"
     ]
    }
   ],
   "source": [
    "    folder_path_train = os.path.join(\"..\", \"data\", \"asl_alphabet_train\", \"asl_alphabet_train\") # Path to the data if unzipped already\n",
    "    if not os.path.exists(folder_path_train): # Checking to see if folder is unzipped\n",
    "        print(\"Unzipping file...\")\n",
    "        path_to_zip = os.path.join(\"..\",\"data\",\"archive1.zip\") # Defining the path to the zip file\n",
    "        zip_destination = os.path.join(\"..\", \"data\") # defining the output destination\n",
    "\n",
    "        with zipfile.ZipFile(path_to_zip,\"r\") as zip_ref: # using the package from zipfile, to un zip the zip file\n",
    "            zip_ref.extractall(zip_destination)\n",
    "    print(\"The files are unzipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are unzipped\n"
     ]
    }
   ],
   "source": [
    "    folder_path_test = os.path.join(\"..\", \"data\", \"real_test_images\") # Path to the data if unzipped already\n",
    "    if not os.path.exists(folder_path_test): # Checking to see if folder is unzipped\n",
    "        print(\"Unzipping file\")\n",
    "        os.makedirs(folder_path) # Making the folder real_test_images\n",
    "        path_to_zip = os.path.join(\"..\",\"data\",\"archive2.zip\") # Defining the path to the zip file\n",
    "        zip_destination = os.path.join(\"..\", \"data\", \"real_test_images\") # defining the output destination\n",
    "\n",
    "        with zipfile.ZipFile(path_to_zip,\"r\") as zip_ref: # using the package from zipfile, to un zip the zip file\n",
    "            zip_ref.extractall(zip_destination)\n",
    "    print(\"The files are unzipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting folders for real_test_images\n",
    "- folder_path_train and folder_path_test is used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: ../data/asl_alphabet_train/asl_alphabet_train/asl-alphabet-test does not exists\n",
      "Folder: ../data/asl_alphabet_train/asl_alphabet_train/del does not exists\n",
      "Folder: ../data/asl_alphabet_train/asl_alphabet_train/nothing does not exists\n",
      "Folder: ../data/asl_alphabet_train/asl_alphabet_train/space does not exists\n",
      "../data/asl_alphabet_test is already deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folders_to_delete = [\"asl-alphabet-test\", \"del\", \"nothing\", \"space\"]  # List of folders to delete\n",
    "\n",
    "for folder_name in folders_to_delete:\n",
    "    folder_path = os.path.join(folder_path_train, folder_name) # Getting folder_path_test from unzip function \n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Deleted folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder: {folder_path} does not exists\")\n",
    "\n",
    "folder_path_asl_test = os.path.join(\"..\",\"data\",\"asl_alphabet_test\")\n",
    "if os.path.exists(folder_path_asl_test):\n",
    "    shutil.rmtree(folder_path_asl_test)\n",
    "    print(f\"Deleted folder_ {folder_path_asl_test}\")\n",
    "else:\n",
    "    print(f\"{folder_path_asl_test} is already deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Image data generator\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Creating Image data generator\")\n",
    "    # ImageDataGenerator from tensorflow \n",
    "    datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                validation_split = 0.2, # Flip it horizontally around the access randomly \n",
    "                                 # Rotate the image randomly 20 degress around the access\n",
    "                                rescale = 1/255 # rescale the pixel values to between 0-1\n",
    "                                \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\"..\",\"data\",\"asl_alphabet_train\", \"asl_alphabet_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62400 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "training_tensorflow = datagen.flow_from_directory(\n",
    "    folder_path_train, # Getting folder from un zip function\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=\"training\",\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15600 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_tensorflow = datagen.flow_from_directory(\n",
    "    folder_path_train,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=\"validation\",\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_test = os.path.join(\"..\",\"data\",\"real_test_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe creation for train images for enabling sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to the directory containing your data\n",
    "data_dir = os.path.join(\"..\",\"data\",\"asl_alphabet_train\",\"asl_alphabet_train\")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists to store image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Iterate through each letter folder in the data directory\n",
    "for label_folder in os.listdir(data_dir):\n",
    "    letter_folder = os.path.join(data_dir, label_folder)\n",
    "\n",
    "    # Iterate through each image file in the letter folder\n",
    "    for filename in os.listdir(letter_folder):\n",
    "        image_path = os.path.join(letter_folder, filename)\n",
    "        images.append(image_path)\n",
    "        # Append the image path and label to the respective lists\n",
    "        image_paths.append(image_path)\n",
    "        labels.append(label_folder)\n",
    "\n",
    "# Create a DataFrame from the image_paths and labels lists\n",
    "train_df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test datagenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_datagen = ImageDataGenerator(                 \n",
    "                                    rescale = 1./255. # Datagenerator for test, it only has to rescale the images \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test flow from dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 780 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "test_tensorflow_ = test_datagen.flow_from_directory(\n",
    "    folder_path_test,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 validated image filenames belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "training_tensorflow = test_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=None,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")\n",
    "\n",
    "#[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: \n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 90, 90, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 90, 90, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 45, 45, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 45, 45, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 45, 45, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 11, 11, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 11, 11, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,884,314\n",
      "Trainable params: 168,602\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Loading model: \")  \n",
    "    # load model without classifier layers\n",
    "    model = VGG16(include_top=False, # Exclude classifier layers\n",
    "                pooling='avg',\n",
    "                input_shape=(90, 90, 3)) # Input shape of the images. 224 pixels by 224. 3 color channels\n",
    "\n",
    "    # Keep pretrained layers, and don't modify them\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    bn = BatchNormalization()(flat1) # Added batnormalization from tensorflow. Take the previouslayer, normalise the values, and than pass them on\n",
    "    class1 = Dense(256, \n",
    "                activation='relu')(bn) # Added new classification layer \n",
    "    class2 = Dense(128, \n",
    "                activation='relu')(class1) # Added new classification layer with 15 outputs. 15 labels in total\n",
    "    output = Dense(26, # 15 labels\n",
    "                activation='softmax')(class2)\n",
    "\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, \n",
    "                outputs=output)\n",
    "\n",
    "    # compile\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01, # Start learning rate at 0.01\n",
    "        decay_steps=10000, # Every 10 000 steps start decaying \n",
    "        decay_rate=0.9) # DEcay by 0.9 to the start learning rate\n",
    "    sgd = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(optimizer=sgd,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 17:25:57.697384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 190s 609ms/step - loss: 0.7275 - accuracy: 0.8345 - val_loss: 1.2914 - val_accuracy: 0.6387\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 126s 402ms/step - loss: 0.5438 - accuracy: 0.8781 - val_loss: 1.2082 - val_accuracy: 0.6621\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 126s 402ms/step - loss: 0.4295 - accuracy: 0.9063 - val_loss: 1.2640 - val_accuracy: 0.6646\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 126s 403ms/step - loss: 0.3530 - accuracy: 0.9245 - val_loss: 1.2152 - val_accuracy: 0.6837\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 126s 404ms/step - loss: 0.2961 - accuracy: 0.9377 - val_loss: 1.2589 - val_accuracy: 0.6819\n"
     ]
    }
   ],
   "source": [
    "    H = model.fit( # fitting the model to \n",
    "        training_tensorflow, # training data from tensorflow dataframe \n",
    "        steps_per_epoch = len(training_tensorflow), # Take as many steps as the length of the dataframe \n",
    "        validation_data = validation_tensorflow, # Validation data from tensorflow dataframe\n",
    "        validation_steps = len(validation_tensorflow), # Validation steps as length of validation data \n",
    "        epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 17:53:16.595030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 37s 6s/step\n"
     ]
    }
   ],
   "source": [
    "    pred = model.predict(test_tensorflow_) # Using test data on the model\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "\n",
    "    # Map the label \n",
    "    labels = (training_tensorflow_.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10000, 780]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_true \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues \u001b[39m# Test labels from dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m classification_report_test \u001b[39m=\u001b[39m classification_report(y_true, pred) \u001b[39m# Create classification report with labels, and predictions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report - Test Data:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(classification_report_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassification_report\u001b[39m(\n\u001b[1;32m   2196\u001b[0m     y_true,\n\u001b[1;32m   2197\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2205\u001b[0m ):\n\u001b[1;32m   2206\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m \n\u001b[1;32m   2208\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2312\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2313\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10000, 780]"
     ]
    }
   ],
   "source": [
    "    y_true = test_df['label'].values # Test labels from dataframe\n",
    "    classification_report_test = classification_report(y_true, pred) # Create classification report with labels, and predictions\n",
    "    print(\"Classification Report - Test Data:\")\n",
    "    print(classification_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.03      0.03      0.03        30\n",
      "           B       0.00      0.00      0.00        30\n",
      "           C       0.00      0.00      0.00        30\n",
      "           D       0.04      0.13      0.06        30\n",
      "           E       0.07      0.10      0.08        30\n",
      "           F       0.03      0.03      0.03        30\n",
      "           G       0.04      0.27      0.07        30\n",
      "           H       0.18      0.07      0.10        30\n",
      "           I       0.00      0.00      0.00        30\n",
      "           J       0.05      0.07      0.06        30\n",
      "           K       0.00      0.00      0.00        30\n",
      "           L       0.25      0.03      0.06        30\n",
      "           M       0.00      0.00      0.00        30\n",
      "           N       0.05      0.03      0.04        30\n",
      "           O       0.06      0.03      0.04        30\n",
      "           P       0.00      0.00      0.00        30\n",
      "           Q       0.00      0.00      0.00        30\n",
      "           R       0.08      0.03      0.05        30\n",
      "           S       0.50      0.03      0.06        30\n",
      "           T       0.00      0.00      0.00        30\n",
      "           U       0.00      0.00      0.00        30\n",
      "           V       0.00      0.00      0.00        30\n",
      "           W       0.00      0.00      0.00        30\n",
      "           X       0.33      0.03      0.06        30\n",
      "           Y       0.05      0.03      0.04        30\n",
      "           Z       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.04       780\n",
      "   macro avg       0.07      0.04      0.03       780\n",
      "weighted avg       0.07      0.04      0.03       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels = test_tensorflow_.classes\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_map = {v: k for k, v in training_tensorflow.class_indices.items()}\n",
    "true_labels = np.array([label_map[label] for label in true_labels])\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5f9c4dae20>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,5), H.history[\"loss\"], label = \"train_loss\")\n",
    "plt.plot(np.arange(0, 5), H.history[\"val_loss\"], label=\"val_loss\", linestyle=\":\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
