{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf tools\n",
    "import tensorflow as tf\n",
    "\n",
    "# image processsing\n",
    "from tensorflow.keras.preprocessing.image import (load_img,\n",
    "                                                  img_to_array,\n",
    "                                                  ImageDataGenerator)\n",
    "# VGG16 model\n",
    "from tensorflow.keras.applications.vgg16 import (preprocess_input,\n",
    "                                                 decode_predictions,\n",
    "                                                 VGG16)\n",
    "# cifar10 data - 32x32\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# layers\n",
    "from tensorflow.keras.layers import (Flatten, \n",
    "                                     Dense, \n",
    "                                     Dropout, \n",
    "                                     BatchNormalization)\n",
    "# generic model object\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping file\n",
      "The files are unzipped\n"
     ]
    }
   ],
   "source": [
    "    folder_path = os.path.join(\"..\", \"data\", \"Test_Alphabet\") # Path to the data if unzipped already\n",
    "    if not os.path.exists(folder_path): # Checking to see if folder is unzipped\n",
    "        print(\"Unzipping file\")\n",
    "        path_to_zip = os.path.join(\"..\",\"data\",\"archive.zip\") # Defining the path to the zip file\n",
    "        zip_destination = os.path.join(\"..\", \"data\") # defining the output destination\n",
    "\n",
    "        with zipfile.ZipFile(path_to_zip,\"r\") as zip_ref: # using the package from zipfile, to un zip the zip file\n",
    "            zip_ref.extractall(zip_destination)\n",
    "    print(\"The files are unzipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting blank folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 39] Directory not empty: '../data/Test_Alphabet/Blank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# check if the folder exists and remove it\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(blank_Test_Alphabet):\n\u001b[0;32m----> 6\u001b[0m     os\u001b[39m.\u001b[39;49mrmdir(blank_Test_Alphabet)\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mblank_Test_Alphabet\u001b[39m}\u001b[39;00m\u001b[39m removed successfully\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(blank_Train_Alphabet):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: '../data/Test_Alphabet/Blank'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image datagenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Image data generator\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Creating Image data generator\")\n",
    "    # ImageDataGenerator from tensorflow \n",
    "    datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                validation_split = 0.2, # Flip it horizontally around the access randomly \n",
    "                                 # Rotate the image randomly 20 degress around the access\n",
    "                                rescale = 1/255 # rescale the pixel values to between 0-1\n",
    "                                \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\"..\",\"data\",\"Train_Alphabet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18720 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "training_tensorflow = datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=\"training\",\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4680 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_tensorflow = datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=\"validation\",\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_datagen = ImageDataGenerator(\n",
    "                                    rescale = 1./255. # Datagenerator for test, it only has to rescale the images \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_test = os.path.join(\"..\",\"data\",\"Test_Alphabet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "test_tensorflow_ = test_datagen.flow_from_directory(\n",
    "    directory_test,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: \n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 90, 90, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 90, 90, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 45, 45, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 45, 45, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 45, 45, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 11, 11, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 11, 11, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,884,314\n",
      "Trainable params: 168,602\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Loading model: \")  \n",
    "    # load model without classifier layers\n",
    "    model = VGG16(include_top=False, # Exclude classifier layers\n",
    "                pooling='avg',\n",
    "                input_shape=(90, 90, 3)) # Input shape of the images. 224 pixels by 224. 3 color channels\n",
    "\n",
    "    # Keep pretrained layers, and don't modify them\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    bn = BatchNormalization()(flat1) # Added batnormalization from tensorflow. Take the previouslayer, normalise the values, and than pass them on\n",
    "    class1 = Dense(256, \n",
    "                activation='relu')(bn) # Added new classification layer \n",
    "    class2 = Dense(128, \n",
    "                activation='relu')(class1) # Added new classification layer with 15 outputs. 15 labels in total\n",
    "    output = Dense(26, # 15 labels\n",
    "                activation='softmax')(class2)\n",
    "\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, \n",
    "                outputs=output)\n",
    "\n",
    "    # compile\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01, # Start learning rate at 0.01\n",
    "        decay_steps=10000, # Every 10 000 steps start decaying \n",
    "        decay_rate=0.9) # DEcay by 0.9 to the start learning rate\n",
    "    sgd = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(optimizer=sgd,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 13:08:46.837974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - ETA: 0s - loss: 2.9458 - accuracy: 0.1683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 13:13:40.272477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 367s 626ms/step - loss: 2.9458 - accuracy: 0.1683 - val_loss: 2.5957 - val_accuracy: 0.2761\n",
      "Epoch 2/5\n",
      "306/585 [==============>...............] - ETA: 2:19 - loss: 2.3924 - accuracy: 0.3264"
     ]
    }
   ],
   "source": [
    "    H = model.fit( # fitting the model to \n",
    "        training_tensorflow, # training data from tensorflow dataframe \n",
    "        steps_per_epoch = len(training_tensorflow), # Take as many steps as the length of the dataframe \n",
    "        validation_data = validation_tensorflow, # Validation data from tensorflow dataframe\n",
    "        validation_steps = len(validation_tensorflow), # Validation steps as length of validation data \n",
    "        epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 12:28:17.796338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 42s 493ms/step\n",
      "['A', 'Y', 'Blank', 'A', 'X', 'A', 'L', 'L', 'Blank', 'Z', 'A', 'A', 'H', 'A', 'A', 'A', 'A', 'L', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'J', 'L', 'A', 'A', 'A', 'A', 'A', 'X', 'N', 'J', 'J', 'F', 'A', 'E', 'A', 'A', 'A', 'A', 'A', 'L', 'H', 'T', 'Z', 'A', 'I', 'A', 'X', 'W', 'N', 'A', 'A', 'A', 'K', 'A', 'A', 'A', 'T', 'G', 'A', 'A', 'P', 'A', 'A', 'A', 'U', 'A', 'T', 'Blank', 'F', 'A', 'A', 'A', 'A', 'L', 'Z', 'A', 'A', 'N', 'A', 'C', 'A', 'I', 'A', 'A', 'M', 'L', 'E', 'A', 'A', 'A', 'Blank', 'A', 'G', 'B', 'B', 'N', 'N', 'B', 'B', 'B', 'L', 'B', 'U', 'A', 'Blank', 'Q', 'I', 'B', 'U', 'Blank', 'B', 'B', 'B', 'L', 'Z', 'B', 'U', 'X', 'I', 'Blank', 'B', 'B', 'Blank', 'B', 'B', 'C', 'Blank', 'M', 'B', 'B', 'L', 'B', 'L', 'B', 'B', 'K', 'B', 'B', 'Z', 'B', 'B', 'B', 'F', 'N', 'Blank', 'U', 'X', 'B', 'U', 'B', 'B', 'U', 'L', 'Blank', 'V', 'Z', 'Blank', 'B', 'Y', 'B', 'B', 'B', 'B', 'I', 'Blank', 'L', 'Blank', 'B', 'B', 'A', 'I', 'B', 'O', 'B', 'L', 'B', 'N', 'M', 'U', 'B', 'Blank', 'U', 'B', 'B', 'B', 'U', 'L', 'B', 'B', 'B', 'B', 'B', 'Q', 'Blank', 'Blank', 'Blank', 'Blank', 'L', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'V', 'Blank', 'Blank', 'Blank', 'Blank', 'G', 'Blank', 'J', 'Blank', 'H', 'Blank', 'Q', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'F', 'Blank', 'L', 'P', 'P', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'F', 'T', 'Blank', 'Blank', 'Blank', 'Blank', 'J', 'Q', 'A', 'Blank', 'Blank', 'L', 'Blank', 'Blank', 'Z', 'Blank', 'Blank', 'Blank', 'P', 'Blank', 'Y', 'Y', 'Blank', 'L', 'A', 'Blank', 'Blank', 'Blank', 'K', 'Blank', 'Blank', 'J', 'Blank', 'Blank', 'Blank', 'V', 'Blank', 'J', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'Blank', 'O', 'C', 'C', 'C', 'C', 'C', 'J', 'C', 'C', 'C', 'K', 'C', 'A', 'H', 'H', 'C', 'C', 'D', 'C', 'C', 'C', 'C', 'C', 'O', 'R', 'C', 'S', 'C', 'C', 'C', 'C', 'J', 'C', 'C', 'C', 'C', 'Blank', 'C', 'C', 'C', 'C', 'W', 'I', 'C', 'C', 'C', 'B', 'X', 'C', 'R', 'C', 'C', 'C', 'J', 'R', 'M', 'T', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'X', 'C', 'C', 'C', 'C', 'T', 'C', 'B', 'C', 'C', 'L', 'C', 'V', 'C', 'C', 'Blank', 'C', 'C', 'C', 'C', 'X', 'C', 'C', 'C', 'O', 'C', 'H', 'C', 'O', 'C', 'A', 'C', 'S', 'C', 'Z', 'Z', 'M', 'D', 'Z', 'C', 'U', 'D', 'D', 'H', 'U', 'L', 'V', 'Z', 'H', 'U', 'D', 'Q', 'R', 'H', 'Z', 'N', 'L', 'D', 'Y', 'U', 'D', 'Z', 'B', 'W', 'T', 'D', 'Q', 'D', 'U', 'D', 'X', 'V', 'I', 'D', 'X', 'J', 'D', 'M', 'D', 'D', 'D', 'C', 'A', 'B', 'Z', 'W', 'G', 'Blank', 'J', 'A', 'E', 'D', 'X', 'B', 'X', 'D', 'Z', 'R', 'D', 'A', 'Q', 'X', 'D', 'D', 'I', 'L', 'D', 'D', 'Q', 'D', 'H', 'L', 'I', 'G', 'A', 'B', 'J', 'V', 'N', 'D', 'X', 'Blank', 'Blank', 'D', 'P', 'D', 'B', 'D', 'K', 'D', 'Z', 'J', 'C', 'D', 'O', 'E', 'A', 'D', 'O', 'M', 'Blank', 'B', 'E', 'M', 'E', 'O', 'J', 'E', 'N', 'O', 'S', 'O', 'L', 'X', 'E', 'N', 'E', 'E', 'Y', 'J', 'S', 'J', 'E', 'O', 'Y', 'M', 'E', 'S', 'J', 'P', 'O', 'I', 'E', 'E', 'T', 'O', 'S', 'J', 'J', 'A', 'E', 'J', 'S', 'S', 'O', 'Q', 'S', 'E', 'O', 'O', 'E', 'K', 'M', 'M', 'E', 'M', 'X', 'P', 'E', 'M', 'C', 'I', 'E', 'E', 'Q', 'I', 'S', 'E', 'M', 'P', 'J', 'M', 'M', 'M', 'N', 'E', 'M', 'M', 'A', 'X', 'E', 'Q', 'N', 'Blank', 'O', 'E', 'N', 'E', 'N', 'Y', 'E', 'U', 'E', 'E', 'F', 'Blank', 'Blank', 'F', 'I', 'V', 'M', 'F', 'Y', 'F', 'E', 'Blank', 'N', 'L', 'F', 'L', 'J', 'F', 'F', 'F', 'L', 'D', 'L', 'X', 'M', 'Y', 'Blank', 'Blank', 'L', 'Blank', 'F', 'F', 'Blank', 'X', 'F', 'A', 'J', 'L', 'F', 'L', 'Blank', 'W', 'L', 'Z', 'L', 'Blank', 'K', 'L', 'N', 'L', 'L', 'O', 'D', 'I', 'L', 'Z', 'F', 'F', 'G', 'L', 'F', 'C', 'V', 'I', 'B', 'I', 'F', 'B', 'E', 'U', 'Blank', 'N', 'L', 'F', 'Blank', 'V', 'Blank', 'L', 'K', 'A', 'G', 'F', 'F', 'F', 'Y', 'F', 'K', 'A', 'F', 'W', 'L', 'F', 'L', 'F', 'B', 'N', 'Y', 'F', 'C', 'E', 'H', 'G', 'G', 'J', 'G', 'Q', 'J', 'G', 'H', 'G', 'G', 'G', 'G', 'G', 'G', 'I', 'G', 'G', 'D', 'G', 'G', 'G', 'N', 'J', 'G', 'H', 'H', 'G', 'G', 'A', 'Blank', 'P', 'G', 'T', 'H', 'H', 'G', 'J', 'G', 'G', 'G', 'G', 'H', 'G', 'H', 'J', 'R', 'H', 'G', 'H', 'G', 'G', 'G', 'G', 'G', 'J', 'G', 'G', 'A', 'X', 'J', 'Q', 'J', 'O', 'Blank', 'H', 'J', 'O', 'G', 'G', 'D', 'G', 'A', 'J', 'J', 'G', 'H', 'J', 'G', 'A', 'G', 'G', 'P', 'J', 'O', 'G', 'J', 'G', 'G', 'G', 'H', 'G', 'R', 'G', 'G', 'P', 'G', 'G', 'H', 'G', 'J', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'J', 'H', 'Blank', 'G', 'G', 'H', 'H', 'P', 'H', 'J', 'H', 'H', 'A', 'H', 'H', 'H', 'H', 'G', 'H', 'H', 'A', 'H', 'H', 'Blank', 'H', 'J', 'J', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'O', 'C', 'R', 'H', 'H', 'Q', 'Blank', 'H', 'H', 'H', 'H', 'Q', 'H', 'H', 'H', 'J', 'H', 'H', 'Q', 'G', 'Q', 'H', 'H', 'H', 'D', 'H', 'Blank', 'H', 'H', 'H', 'H', 'A', 'H', 'G', 'G', 'Blank', 'G', 'J', 'Q', 'H', 'H', 'H', 'H', 'J', 'C', 'G', 'H', 'H', 'H', 'H', 'H', 'H', 'Blank', 'H', 'H', 'H', 'I', 'V', 'I', 'U', 'Blank', 'I', 'T', 'I', 'K', 'D', 'I', 'N', 'I', 'V', 'U', 'I', 'I', 'I', 'I', 'B', 'R', 'V', 'I', 'A', 'U', 'Z', 'M', 'R', 'I', 'U', 'B', 'Y', 'V', 'I', 'I', 'U', 'L', 'V', 'I', 'B', 'O', 'I', 'B', 'Y', 'K', 'I', 'X', 'I', 'Z', 'I', 'W', 'I', 'I', 'A', 'I', 'I', 'Q', 'X', 'I', 'N', 'I', 'I', 'O', 'R', 'O', 'I', 'B', 'I', 'I', 'I', 'I', 'B', 'D', 'Z', 'I', 'I', 'H', 'I', 'F', 'B', 'Y', 'I', 'B', 'I', 'I', 'C', 'C', 'I', 'I', 'R', 'F', 'I', 'Blank', 'D', 'X', 'Z', 'C', 'I', 'B', 'I', 'J', 'E', 'G', 'Q', 'J', 'J', 'J', 'M', 'P', 'Q', 'H', 'E', 'M', 'J', 'G', 'J', 'H', 'J', 'Q', 'J', 'J', 'J', 'Q', 'L', 'J', 'Q', 'J', 'G', 'B', 'P', 'J', 'G', 'G', 'J', 'J', 'Q', 'O', 'Blank', 'J', 'Q', 'H', 'J', 'G', 'Q', 'J', 'Y', 'H', 'K', 'A', 'T', 'A', 'Q', 'P', 'T', 'J', 'Q', 'G', 'N', 'H', 'P', 'J', 'J', 'J', 'J', 'J', 'J', 'G', 'J', 'Blank', 'J', 'H', 'Blank', 'J', 'J', 'Q', 'T', 'J', 'J', 'J', 'J', 'J', 'J', 'G', 'H', 'F', 'J', 'H', 'J', 'J', 'J', 'T', 'D', 'P', 'N', 'J', 'J', 'J', 'P', 'Q', 'J', 'F', 'Z', 'B', 'F', 'F', 'N', 'C', 'Blank', 'Y', 'X', 'L', 'B', 'Y', 'W', 'K', 'Z', 'K', 'K', 'G', 'W', 'V', 'R', 'B', 'V', 'L', 'K', 'K', 'K', 'V', 'K', 'U', 'R', 'N', 'F', 'K', 'Blank', 'A', 'K', 'V', 'U', 'F', 'W', 'V', 'U', 'X', 'Y', 'N', 'V', 'V', 'E', 'N', 'W', 'L', 'Y', 'R', 'Y', 'V', 'U', 'K', 'W', 'X', 'K', 'L', 'K', 'B', 'D', 'F', 'F', 'V', 'K', 'K', 'W', 'O', 'Y', 'F', 'I', 'A', 'G', 'W', 'H', 'X', 'K', 'F', 'H', 'V', 'I', 'B', 'K', 'K', 'K', 'R', 'V', 'K', 'D', 'B', 'R', 'K', 'V', 'V', 'Y', 'Z', 'Z', 'L', 'F', 'D', 'L', 'L', 'P', 'L', 'O', 'L', 'L', 'K', 'A', 'J', 'L', 'J', 'Y', 'L', 'L', 'W', 'N', 'F', 'Blank', 'L', 'L', 'L', 'L', 'Blank', 'L', 'L', 'L', 'N', 'L', 'L', 'A', 'A', 'M', 'K', 'L', 'Q', 'L', 'D', 'Z', 'J', 'Q', 'Z', 'L', 'X', 'L', 'D', 'L', 'L', 'T', 'L', 'L', 'F', 'L', 'L', 'L', 'B', 'L', 'L', 'Q', 'F', 'L', 'L', 'L', 'L', 'L', 'A', 'L', 'J', 'L', 'K', 'Blank', 'L', 'L', 'F', 'L', 'Z', 'L', 'Z', 'L', 'K', 'Q', 'L', 'L', 'V', 'X', 'L', 'L', 'J', 'C', 'L', 'Y', 'Y', 'U', 'H', 'L', 'J', 'M', 'J', 'U', 'Blank', 'I', 'P', 'N', 'M', 'F', 'T', 'F', 'N', 'O', 'T', 'M', 'T', 'S', 'E', 'N', 'N', 'M', 'N', 'P', 'E', 'E', 'M', 'M', 'R', 'D', 'B', 'N', 'O', 'E', 'M', 'M', 'Blank', 'N', 'N', 'Blank', 'B', 'I', 'Z', 'S', 'M', 'T', 'M', 'I', 'G', 'J', 'N', 'Blank', 'U', 'S', 'N', 'M', 'S', 'E', 'X', 'M', 'M', 'N', 'M', 'C', 'M', 'Z', 'M', 'S', 'M', 'B', 'S', 'N', 'T', 'P', 'E', 'X', 'S', 'M', 'N', 'P', 'J', 'P', 'Blank', 'J', 'M', 'N', 'F', 'L', 'M', 'O', 'S', 'N', 'Z', 'M', 'S', 'N', 'B', 'R', 'M', 'L', 'N', 'Blank', 'N', 'N', 'N', 'Blank', 'N', 'J', 'N', 'N', 'J', 'J', 'H', 'M', 'B', 'E', 'A', 'N', 'N', 'M', 'X', 'M', 'W', 'G', 'E', 'P', 'F', 'L', 'N', 'N', 'Z', 'F', 'Blank', 'Y', 'U', 'Z', 'D', 'T', 'N', 'E', 'I', 'O', 'N', 'N', 'F', 'M', 'N', 'E', 'Q', 'A', 'M', 'A', 'Blank', 'N', 'M', 'O', 'P', 'X', 'B', 'M', 'V', 'L', 'T', 'U', 'Q', 'M', 'I', 'N', 'N', 'N', 'Q', 'S', 'N', 'N', 'O', 'T', 'E', 'M', 'A', 'G', 'Z', 'G', 'N', 'C', 'N', 'M', 'N', 'J', 'Z', 'M', 'V', 'N', 'E', 'L', 'N', 'M', 'T', 'J', 'E', 'T', 'O', 'O', 'C', 'E', 'O', 'C', 'O', 'O', 'O', 'O', 'C', 'C', 'O', 'B', 'O', 'O', 'C', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'H', 'O', 'O', 'O', 'O', 'O', 'S', 'O', 'A', 'I', 'F', 'O', 'D', 'E', 'W', 'Blank', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'H', 'O', 'O', 'O', 'O', 'O', 'S', 'H', 'O', 'H', 'S', 'O', 'C', 'O', 'O', 'O', 'Blank', 'C', 'B', 'O', 'C', 'O', 'C', 'O', 'O', 'O', 'H', 'O', 'O', 'L', 'T', 'I', 'Q', 'O', 'O', 'T', 'C', 'O', 'O', 'O', 'O', 'P', 'P', 'M', 'Q', 'P', 'N', 'L', 'P', 'M', 'J', 'G', 'Q', 'P', 'Q', 'Q', 'Q', 'Q', 'P', 'Q', 'P', 'P', 'Blank', 'Blank', 'P', 'S', 'B', 'G', 'Blank', 'Q', 'V', 'L', 'L', 'G', 'L', 'Q', 'P', 'P', 'P', 'K', 'P', 'G', 'G', 'P', 'J', 'P', 'P', 'L', 'P', 'J', 'Blank', 'J', 'Q', 'P', 'P', 'P', 'Blank', 'Blank', 'Q', 'Blank', 'Q', 'J', 'N', 'Q', 'J', 'E', 'J', 'P', 'J', 'Q', 'P', 'A', 'P', 'Blank', 'P', 'Q', 'G', 'A', 'X', 'P', 'Q', 'Q', 'Blank', 'P', 'P', 'J', 'J', 'P', 'P', 'P', 'P', 'P', 'J', 'P', 'J', 'J', 'Blank', 'P', 'V', 'J', 'P', 'C', 'P', 'J', 'P', 'G', 'Blank', 'P', 'Blank', 'Q', 'P', 'Blank', 'P', 'Blank', 'P', 'H', 'Q', 'J', 'W', 'Blank', 'Q', 'S', 'A', 'P', 'J', 'Q', 'P', 'Z', 'J', 'J', 'H', 'Blank', 'P', 'P', 'P', 'Blank', 'Z', 'M', 'J', 'J', 'Q', 'M', 'A', 'Blank', 'Q', 'H', 'I', 'H', 'J', 'J', 'Blank', 'J', 'Q', 'L', 'J', 'P', 'L', 'Q', 'P', 'J', 'Q', 'J', 'P', 'P', 'G', 'Q', 'Q', 'P', 'X', 'F', 'Q', 'J', 'Q', 'Q', 'J', 'J', 'O', 'D', 'J', 'J', 'P', 'E', 'P', 'P', 'Z', 'Q', 'X', 'J', 'P', 'Q', 'J', 'Q', 'P', 'Blank', 'Blank', 'P', 'N', 'P', 'P', 'B', 'P', 'R', 'R', 'V', 'R', 'R', 'Blank', 'R', 'B', 'I', 'R', 'R', 'R', 'F', 'Blank', 'R', 'R', 'I', 'R', 'R', 'R', 'W', 'B', 'R', 'R', 'U', 'R', 'C', 'R', 'X', 'O', 'Blank', 'I', 'H', 'X', 'R', 'W', 'R', 'R', 'K', 'X', 'U', 'Y', 'R', 'X', 'D', 'K', 'Blank', 'Q', 'D', 'R', 'K', 'C', 'R', 'R', 'P', 'U', 'D', 'U', 'F', 'Q', 'R', 'Y', 'R', 'E', 'P', 'K', 'A', 'F', 'X', 'R', 'R', 'K', 'N', 'V', 'L', 'R', 'V', 'A', 'O', 'Blank', 'R', 'L', 'I', 'N', 'D', 'R', 'C', 'R', 'C', 'R', 'A', 'C', 'U', 'R', 'R', 'R', 'Y', 'V', 'A', 'W', 'S', 'T', 'O', 'T', 'S', 'P', 'S', 'N', 'S', 'O', 'S', 'S', 'Z', 'G', 'S', 'S', 'S', 'S', 'X', 'H', 'S', 'Z', 'S', 'Blank', 'X', 'W', 'S', 'O', 'H', 'S', 'O', 'S', 'Q', 'C', 'S', 'Blank', 'S', 'Blank', 'S', 'D', 'S', 'O', 'S', 'S', 'S', 'K', 'S', 'Z', 'S', 'S', 'H', 'N', 'S', 'S', 'T', 'T', 'X', 'P', 'S', 'B', 'S', 'S', 'S', 'Blank', 'S', 'O', 'O', 'T', 'T', 'T', 'I', 'S', 'S', 'S', 'M', 'S', 'S', 'S', 'M', 'O', 'T', 'S', 'S', 'S', 'Z', 'S', 'S', 'M', 'S', 'T', 'S', 'Q', 'O', 'S', 'S', 'S', 'S', 'T', 'T', 'R', 'T', 'P', 'L', 'T', 'O', 'G', 'T', 'O', 'T', 'J', 'T', 'G', 'N', 'B', 'O', 'T', 'T', 'T', 'T', 'S', 'L', 'E', 'L', 'S', 'B', 'T', 'M', 'T', 'R', 'T', 'A', 'T', 'T', 'S', 'H', 'J', 'E', 'S', 'T', 'T', 'T', 'I', 'T', 'O', 'O', 'S', 'T', 'T', 'O', 'L', 'N', 'H', 'M', 'T', 'N', 'T', 'G', 'T', 'E', 'T', 'T', 'S', 'Blank', 'N', 'P', 'N', 'T', 'N', 'R', 'F', 'T', 'M', 'T', 'T', 'G', 'T', 'T', 'T', 'T', 'O', 'A', 'T', 'M', 'S', 'T', 'J', 'M', 'T', 'Blank', 'J', 'C', 'T', 'T', 'A', 'T', 'T', 'Blank', 'M', 'T', 'J', 'I', 'R', 'B', 'Y', 'D', 'U', 'Y', 'A', 'U', 'R', 'U', 'B', 'R', 'N', 'U', 'U', 'X', 'I', 'U', 'Y', 'Q', 'R', 'U', 'I', 'R', 'M', 'U', 'Blank', 'A', 'V', 'V', 'B', 'F', 'Q', 'L', 'L', 'W', 'L', 'L', 'B', 'D', 'L', 'U', 'L', 'L', 'D', 'A', 'U', 'V', 'U', 'C', 'U', 'H', 'N', 'R', 'U', 'U', 'Blank', 'R', 'U', 'A', 'B', 'U', 'U', 'K', 'U', 'X', 'Blank', 'K', 'B', 'U', 'U', 'U', 'Q', 'L', 'R', 'B', 'W', 'U', 'U', 'R', 'U', 'O', 'V', 'U', 'V', 'U', 'U', 'N', 'D', 'U', 'Blank', 'K', 'L', 'U', 'L', 'U', 'I', 'Blank', 'D', 'W', 'L', 'B', 'K', 'A', 'V', 'K', 'V', 'W', 'W', 'U', 'V', 'A', 'J', 'D', 'B', 'I', 'V', 'L', 'Blank', 'V', 'Blank', 'L', 'K', 'B', 'V', 'W', 'V', 'I', 'R', 'B', 'D', 'V', 'F', 'V', 'X', 'R', 'W', 'V', 'Q', 'V', 'D', 'V', 'K', 'N', 'W', 'A', 'D', 'V', 'V', 'A', 'A', 'V', 'L', 'K', 'L', 'W', 'V', 'W', 'Z', 'V', 'V', 'P', 'B', 'W', 'V', 'V', 'J', 'V', 'I', 'Blank', 'L', 'V', 'Blank', 'U', 'V', 'F', 'V', 'E', 'V', 'V', 'B', 'W', 'C', 'Blank', 'D', 'W', 'D', 'Z', 'W', 'D', 'L', 'V', 'K', 'A', 'W', 'Y', 'Blank', 'R', 'D', 'V', 'W', 'Z', 'W', 'W', 'Y', 'V', 'W', 'W', 'F', 'Z', 'Blank', 'J', 'Blank', 'A', 'I', 'W', 'W', 'I', 'Blank', 'Z', 'A', 'W', 'W', 'Q', 'W', 'D', 'F', 'I', 'I', 'Blank', 'V', 'W', 'W', 'V', 'L', 'W', 'W', 'A', 'V', 'W', 'Z', 'W', 'L', 'W', 'V', 'B', 'W', 'W', 'L', 'A', 'D', 'W', 'K', 'W', 'Z', 'E', 'W', 'W', 'V', 'Blank', 'B', 'K', 'M', 'K', 'L', 'W', 'L', 'W', 'G', 'Z', 'F', 'A', 'F', 'L', 'W', 'F', 'W', 'P', 'U', 'F', 'A', 'W', 'V', 'A', 'L', 'W', 'F', 'W', 'U', 'R', 'W', 'A', 'A', 'W', 'W', 'H', 'I', 'W', 'L', 'X', 'D', 'B', 'R', 'M', 'X', 'G', 'X', 'T', 'Blank', 'V', 'X', 'O', 'F', 'X', 'X', 'D', 'X', 'X', 'J', 'W', 'F', 'X', 'U', 'X', 'N', 'D', 'X', 'Blank', 'H', 'L', 'R', 'L', 'C', 'T', 'N', 'C', 'X', 'N', 'Z', 'O', 'D', 'X', 'N', 'N', 'Y', 'L', 'W', 'Blank', 'Q', 'D', 'X', 'D', 'O', 'W', 'X', 'U', 'U', 'X', 'X', 'X', 'R', 'X', 'T', 'X', 'X', 'X', 'N', 'D', 'J', 'R', 'S', 'X', 'X', 'P', 'K', 'Z', 'I', 'Blank', 'C', 'U', 'L', 'E', 'L', 'X', 'P', 'X', 'J', 'X', 'Y', 'X', 'R', 'X', 'X', 'X', 'R', 'P', 'X', 'X', 'O', 'I', 'F', 'Y', 'A', 'X', 'N', 'B', 'B', 'W', 'A', 'X', 'Blank', 'Y', 'B', 'L', 'Y', 'A', 'L', 'L', 'Y', 'A', 'B', 'Y', 'K', 'Y', 'L', 'F', 'L', 'N', 'Blank', 'N', 'K', 'B', 'Y', 'L', 'A', 'P', 'Y', 'A', 'Z', 'J', 'L', 'F', 'V', 'D', 'U', 'Y', 'J', 'Y', 'A', 'A', 'Y', 'L', 'X', 'F', 'Blank', 'Q', 'Blank', 'Q', 'L', 'Y', 'I', 'X', 'W', 'B', 'Y', 'A', 'A', 'I', 'D', 'V', 'Y', 'Y', 'Y', 'A', 'Y', 'Blank', 'D', 'N', 'W', 'V', 'V', 'D', 'Blank', 'W', 'A', 'A', 'V', 'Y', 'W', 'Y', 'Z', 'A', 'A', 'Y', 'Y', 'N', 'A', 'W', 'X', 'Blank', 'V', 'L', 'Blank', 'N', 'Y', 'Z', 'Blank', 'Z', 'A', 'D', 'Z', 'D', 'Z', 'Z', 'Z', 'P', 'Z', 'Z', 'D', 'Y', 'Z', 'D', 'G', 'P', 'L', 'C', 'Z', 'Z', 'Z', 'Z', 'Blank', 'J', 'B', 'Z', 'Z', 'D', 'Z', 'Z', 'D', 'W', 'Q', 'Z', 'Z', 'D', 'U', 'Blank', 'D', 'Z', 'Z', 'Q', 'Blank', 'P', 'D', 'L', 'X', 'Blank', 'Z', 'L', 'W', 'D', 'X', 'Z', 'Z', 'L', 'Z', 'Z', 'Blank', 'G', 'L', 'Z', 'D', 'Z', 'L', 'W', 'Y', 'Z', 'K', 'A', 'L', 'D', 'M', 'B', 'Z', 'Z', 'I', 'Z', 'J', 'L', 'Z', 'V', 'Blank', 'Z', 'L', 'Z', 'Z', 'Z', 'X', 'L', 'F']\n"
     ]
    }
   ],
   "source": [
    "# Code taken from source in readme file\n",
    "# Testing the model\n",
    "print(\"Testing model with test images\")\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_tensorflow_) # Using test data on the model\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label \n",
    "labels = (training_tensorflow.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict((v,k) for k,v in labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.39      0.55      0.45       100\n",
      "           B       0.41      0.47      0.44       100\n",
      "       Blank       0.36      0.74      0.49       100\n",
      "           C       0.62      0.66      0.64       100\n",
      "           D       0.30      0.28      0.29       100\n",
      "           E       0.44      0.26      0.33       100\n",
      "           F       0.33      0.25      0.28       100\n",
      "           G       0.52      0.50      0.51       100\n",
      "           H       0.54      0.64      0.58       100\n",
      "           I       0.45      0.42      0.44       100\n",
      "           J       0.28      0.43      0.34       100\n",
      "           K       0.34      0.20      0.25       100\n",
      "           L       0.29      0.49      0.37       100\n",
      "           M       0.29      0.22      0.25       100\n",
      "           N       0.26      0.26      0.26       100\n",
      "           O       0.52      0.63      0.57       100\n",
      "           P       0.35      0.35      0.35       100\n",
      "           Q       0.20      0.17      0.18       100\n",
      "           R       0.47      0.36      0.41       100\n",
      "           S       0.60      0.49      0.54       100\n",
      "           T       0.50      0.41      0.45       100\n",
      "           U       0.39      0.30      0.34       100\n",
      "           V       0.32      0.27      0.29       100\n",
      "           W       0.41      0.34      0.37       100\n",
      "           X       0.37      0.33      0.35       100\n",
      "           Y       0.34      0.21      0.26       100\n",
      "           Z       0.40      0.37      0.38       100\n",
      "\n",
      "    accuracy                           0.39      2700\n",
      "   macro avg       0.40      0.39      0.39      2700\n",
      "weighted avg       0.40      0.39      0.39      2700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels = test_tensorflow_.classes\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_map = {v: k for k, v in training_tensorflow.class_indices.items()}\n",
    "true_labels = np.array([label_map[label] for label in true_labels])\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
