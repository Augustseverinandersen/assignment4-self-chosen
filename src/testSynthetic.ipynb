{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 11:50:22.442075: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# tf tools\n",
    "import tensorflow as tf\n",
    "\n",
    "# image processsing\n",
    "from tensorflow.keras.preprocessing.image import (load_img,\n",
    "                                                  img_to_array,\n",
    "                                                  ImageDataGenerator)\n",
    "# VGG16 model\n",
    "from tensorflow.keras.applications.vgg16 import (preprocess_input,\n",
    "                                                 decode_predictions,\n",
    "                                                 VGG16)\n",
    "# cifar10 data - 32x32\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# layers\n",
    "from tensorflow.keras.layers import (Flatten, \n",
    "                                     Dense, \n",
    "                                     Dropout, \n",
    "                                     BatchNormalization)\n",
    "# generic model object\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are unzipped\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'zip_destination' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         zip_ref\u001b[39m.\u001b[39mextractall(zip_destination)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe files are unzipped\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[39mprint\u001b[39m(zip_destination)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'zip_destination' is not defined"
     ]
    }
   ],
   "source": [
    "    folder_path = os.path.join(\"..\", \"data\", \"Test_Alphabet\") # Path to the data if unzipped already\n",
    "    if not os.path.exists(folder_path): # Checking to see if folder is unzipped\n",
    "        print(\"Unzipping file\")\n",
    "        path_to_zip = os.path.join(\"..\",\"data\",\"archive.zip\") # Defining the path to the zip file\n",
    "        zip_destination = os.path.join(\"..\", \"data\") # defining the output destination\n",
    "\n",
    "        with zipfile.ZipFile(path_to_zip,\"r\") as zip_ref: # using the package from zipfile, to un zip the zip file\n",
    "            zip_ref.extractall(zip_destination)\n",
    "        \n",
    "    print(\"The files are unzipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting blank folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 39] Directory not empty: '../data/Test_Alphabet/Blank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# check if the folder exists and remove it\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(blank_Test_Alphabet):\n\u001b[0;32m----> 6\u001b[0m     os\u001b[39m.\u001b[39;49mrmdir(blank_Test_Alphabet)\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mblank_Test_Alphabet\u001b[39m}\u001b[39;00m\u001b[39m removed successfully\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(blank_Train_Alphabet):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: '../data/Test_Alphabet/Blank'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image datagenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Image data generator\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Creating Image data generator\")\n",
    "    # ImageDataGenerator from tensorflow \n",
    "    datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                validation_split = 0.2, # Flip it horizontally around the access randomly \n",
    "                                 # Rotate the image randomly 20 degress around the access\n",
    "                                rescale = 1/255 # rescale the pixel values to between 0-1\n",
    "                                \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(\"..\",\"data\",\"Train_Alphabet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18720 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "training_tensorflow = datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=\"training\",\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4680 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_tensorflow = datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    subset=\"validation\",\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_datagen = ImageDataGenerator(\n",
    "                                    rescale = 1./255. # Datagenerator for test, it only has to rescale the images \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_test = os.path.join(\"..\",\"data\",\"Test_Alphabet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "test_tensorflow_ = test_datagen.flow_from_directory(\n",
    "    directory_test,\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    #save_to_dir=None,\n",
    "    #save_prefix='',\n",
    "    #save_format='png',\n",
    "    #follow_links=False,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 90, 90, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 90, 90, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 45, 45, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 45, 45, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 45, 45, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 11, 11, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 11, 11, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,884,314\n",
      "Trainable params: 168,602\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"Loading model: \")  \n",
    "    # load model without classifier layers\n",
    "    model = VGG16(include_top=False, # Exclude classifier layers\n",
    "                pooling='avg',\n",
    "                input_shape=(90, 90, 3)) # Input shape of the images. 224 pixels by 224. 3 color channels\n",
    "\n",
    "    # Keep pretrained layers, and don't modify them\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    bn = BatchNormalization()(flat1) # Added batnormalization from tensorflow. Take the previouslayer, normalise the values, and than pass them on\n",
    "    class1 = Dense(256, \n",
    "                activation='relu')(bn) # Added new classification layer \n",
    "    class2 = Dense(128, \n",
    "                activation='relu')(class1) # Added new classification layer with 15 outputs. 15 labels in total\n",
    "    output = Dense(26, # 15 labels\n",
    "                activation='softmax')(class2)\n",
    "\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, \n",
    "                outputs=output)\n",
    "\n",
    "    # compile\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01, # Start learning rate at 0.01\n",
    "        decay_steps=10000, # Every 10 000 steps start decaying \n",
    "        decay_rate=0.9) # DEcay by 0.9 to the start learning rate\n",
    "    sgd = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(optimizer=sgd,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:30:43.173703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - ETA: 0s - loss: 2.9869 - accuracy: 0.1561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:59:22.470276: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 2200s 4s/step - loss: 2.9869 - accuracy: 0.1561 - val_loss: 2.6286 - val_accuracy: 0.2733\n",
      "Epoch 2/5\n",
      "585/585 [==============================] - 1394s 2s/step - loss: 2.3219 - accuracy: 0.3315 - val_loss: 2.1597 - val_accuracy: 0.3682\n",
      "Epoch 3/5\n",
      "585/585 [==============================] - 1246s 2s/step - loss: 1.9837 - accuracy: 0.4188 - val_loss: 1.9360 - val_accuracy: 0.4256\n",
      "Epoch 4/5\n",
      "585/585 [==============================] - 235s 401ms/step - loss: 1.7982 - accuracy: 0.4644 - val_loss: 1.8187 - val_accuracy: 0.4632\n",
      "Epoch 5/5\n",
      "585/585 [==============================] - 233s 399ms/step - loss: 1.6783 - accuracy: 0.4987 - val_loss: 1.7511 - val_accuracy: 0.4808\n"
     ]
    }
   ],
   "source": [
    "    H = model.fit( # fitting the model to \n",
    "        training_tensorflow, # training data from tensorflow dataframe \n",
    "        steps_per_epoch = len(training_tensorflow), # Take as many steps as the length of the dataframe \n",
    "        validation_data = validation_tensorflow, # Validation data from tensorflow dataframe\n",
    "        validation_steps = len(validation_tensorflow), # Validation steps as length of validation data \n",
    "        epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 17:00:06.730652: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 26s 314ms/step\n"
     ]
    }
   ],
   "source": [
    "# Code taken from source in readme file\n",
    "# Testing the model\n",
    "print(\"Testing model with test images\")\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_tensorflow_) # Using test data on the model\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label \n",
    "labels = (training_tensorflow.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict((v,k) for k,v in labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.55      0.59      0.57       100\n",
      "           B       0.40      0.65      0.50       100\n",
      "           C       0.75      0.67      0.71       100\n",
      "           D       0.52      0.44      0.48       100\n",
      "           E       0.36      0.35      0.36       100\n",
      "           F       0.40      0.44      0.42       100\n",
      "           G       0.64      0.61      0.63       100\n",
      "           H       0.69      0.70      0.70       100\n",
      "           I       0.54      0.61      0.57       100\n",
      "           J       0.44      0.48      0.46       100\n",
      "           K       0.44      0.24      0.31       100\n",
      "           L       0.40      0.62      0.49       100\n",
      "           M       0.36      0.36      0.36       100\n",
      "           N       0.38      0.30      0.34       100\n",
      "           O       0.64      0.71      0.67       100\n",
      "           P       0.51      0.46      0.48       100\n",
      "           Q       0.34      0.45      0.38       100\n",
      "           R       0.47      0.47      0.47       100\n",
      "           S       0.50      0.55      0.52       100\n",
      "           T       0.57      0.50      0.53       100\n",
      "           U       0.41      0.39      0.40       100\n",
      "           V       0.47      0.37      0.42       100\n",
      "           W       0.50      0.44      0.47       100\n",
      "           X       0.51      0.45      0.48       100\n",
      "           Y       0.51      0.43      0.46       100\n",
      "           Z       0.57      0.42      0.48       100\n",
      "\n",
      "    accuracy                           0.49      2600\n",
      "   macro avg       0.49      0.49      0.49      2600\n",
      "weighted avg       0.49      0.49      0.49      2600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels = test_tensorflow_.classes\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_map = {v: k for k, v in training_tensorflow.class_indices.items()}\n",
    "true_labels = np.array([label_map[label] for label in true_labels])\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = os.path.join(\"..\",\"models\", \"fake_model.keras\") # Defining out path\n",
    "tf.keras.models.save_model( # Using Tensor Flows function for saving models.\n",
    "model, folder_path, overwrite=False, save_format=None \n",
    ") # Model name, folder, Overwrite existing saves, save format = none "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying on real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to the directory containing your data\n",
    "data_dir = os.path.join(\"..\",\"data\",\"asl_alphabet_train\",\"asl_alphabet_train\")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists to store image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Iterate through each letter folder in the data directory\n",
    "for label_folder in os.listdir(data_dir):\n",
    "    letter_folder = os.path.join(data_dir, label_folder)\n",
    "\n",
    "    # Iterate through each image file in the letter folder\n",
    "    for filename in os.listdir(letter_folder):\n",
    "        image_path = os.path.join(letter_folder, filename)\n",
    "        images.append(image_path)\n",
    "        # Append the image path and label to the respective lists\n",
    "        image_paths.append(image_path)\n",
    "        labels.append(label_folder)\n",
    "\n",
    "# Create a DataFrame from the image_paths and labels lists\n",
    "train_df = pd.DataFrame({'image_path': image_paths, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dataframe = pd.DataFrame(columns = [\"image_path\", \"label\"]) # Creating empty dataframe\n",
    "\n",
    "labels_grouped = train_df.groupby(\"label\") # Grouping the dataframe by label\n",
    "\n",
    "for label, group in labels_grouped: # takes the first 100 of each label and concatinates them into the new dataframe\n",
    "    test_images = group.head(100)\n",
    "    test_images_dataframe = pd.concat([test_images_dataframe, test_images]) \n",
    "\n",
    "train_df = train_df.drop(test_images_dataframe.index) # Removing the images with the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_tensorflow_ = test_datagen.flow_from_dataframe(\n",
    "    test_images_dataframe,\n",
    "    directory=None,\n",
    "    x_col='image_path',\n",
    "    target_size=(90, 90),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=None\n",
    ")\n",
    "\n",
    "#[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 17:07:53.664855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 132s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Code taken from source in readme file\n",
    "# Testing the model\n",
    "print(\"Testing model with test images\")\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_tensorflow_) # Using test data on the model\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label \n",
    "labels = (training_tensorflow.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.12      0.06       100\n",
      "           B       0.53      0.18      0.27       100\n",
      "           C       0.08      0.19      0.12       100\n",
      "           D       0.04      0.02      0.03       100\n",
      "           E       0.14      0.21      0.17       100\n",
      "           F       0.11      0.17      0.13       100\n",
      "           G       0.10      0.06      0.08       100\n",
      "           H       0.16      0.26      0.20       100\n",
      "           I       0.27      0.07      0.11       100\n",
      "           J       0.02      0.01      0.01       100\n",
      "           K       0.32      0.13      0.18       100\n",
      "           L       0.28      0.16      0.20       100\n",
      "           M       0.13      0.02      0.03       100\n",
      "           N       0.33      0.02      0.04       100\n",
      "           O       0.66      0.31      0.42       100\n",
      "           P       0.02      0.05      0.03       100\n",
      "           Q       0.12      0.08      0.10       100\n",
      "           R       0.09      0.02      0.03       100\n",
      "           S       0.35      0.21      0.26       100\n",
      "           T       0.09      0.12      0.11       100\n",
      "           U       0.19      0.13      0.16       100\n",
      "           V       0.05      0.02      0.03       100\n",
      "           W       0.18      0.20      0.19       100\n",
      "           X       0.05      0.10      0.06       100\n",
      "           Y       0.14      0.32      0.19       100\n",
      "           Z       0.03      0.01      0.01       100\n",
      "\n",
      "    accuracy                           0.12      2600\n",
      "   macro avg       0.17      0.12      0.12      2600\n",
      "weighted avg       0.17      0.12      0.12      2600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels = test_images_dataframe[\"label\"].values\n",
    "print(classification_report(true_labels, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
